{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import rake\n",
    "from keywords import TweetKeywords\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "import time\n",
    "from random import shuffle\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local\").setAppName(\"twitter-app\").set(\"spark.kryoserializer.buffer.max\", \"1g\"))\n",
    "sc = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.337321043\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Word2Vec.load_word2vec_format('../../word2vec_twitter_model/word2vec_twitter_model.bin',binary=True, encoding='latin-1')\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# averages words vectors for a tweet\n",
    "def average_word_vecs(words):\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        word = word.replace('\\n', '')\n",
    "        try:\n",
    "            vecs.append(model[word]) #.reshape((1,size_dimension))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if len(vecs) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        vecs = np.average(vecs,axis=0)\n",
    "        return np.array(vecs, dtype='float') #TSNE expects float type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vecs: an array of real vectors\n",
    "def cosine_cluster(vecs, min_similarity):\n",
    "    cluster_vec = []         # tracks sum of vectors in a cluster\n",
    "    cluster_idx_master = []         # array of index arrays. e.g. [[1, 3, 5], [2, 4, 6]]\n",
    "    n_cluster = 0\n",
    "    N = len(vecs)\n",
    "    \n",
    "    for i in range(1, N):\n",
    "        max_similarity = -np.inf\n",
    "        max_idx = 0\n",
    "        v = vecs[i]\n",
    "        if not all(t==0 for t in v):\n",
    "            cluster_sims = [1-scipy.spatial.distance.cosine(v, cluster_vec[j]) for j in range(n_cluster)]\n",
    "\n",
    "            if len(cluster_sims)==0: cluster_sims.append(max_similarity)\n",
    "            max_similarity = max(cluster_sims)\n",
    "            #print cluster_sims\n",
    "            if max_similarity < min_similarity:\n",
    "                # create new cluster\n",
    "                cluster_vec.append(v)\n",
    "                cluster_idx_master.append([i])\n",
    "                n_cluster += 1\n",
    "            else:\n",
    "                test = [idx for idx, sim in enumerate(cluster_sims) if sim == max_similarity]\n",
    "                cluster_idx = [idx for idx, sim in enumerate(cluster_sims) if sim == max_similarity][0]\n",
    "                cluster_vec[cluster_idx] = np.add(cluster_vec[cluster_idx], v)\n",
    "                cluster_idx_master[cluster_idx].append(i)\n",
    "    return cluster_idx_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer(preserve_case=True,reduce_len=True,strip_handles=True)\n",
    "keyword_extractor = TweetKeywords(tknzr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = sql_context.read.json('../../lowes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text=u'@Caljammr home remodeling project! Buying 6k floors from Lowes. Chase ink plus to earn 5x points on gift cards at staples!'),\n",
       " Row(text=u'RT @SCStocks: $ECOB Cheap stock at .0002 #LotteryTicket ready to lift finally. Lockout in place #Sales #HomeDepot #Lowes #RT\\nhttps://t.co/K\\u2026')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.select(['text']).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_tokenize_udf = udf(keyword_extractor.tweet_tokenizer,returnType=ArrayType(StringType(),False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = corpus.select('*',clean_tokenize_udf('text').alias('clean_text')).select('clean_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(clean_text=[u'home', u'remodeling', u'project', u'Buying', u'6k', u'floors', u'from', u'Lowes', u'Chase', u'ink', u'plus', u'to', u'earn', u'5x', u'points', u'on', u'gift', u'cards', u'at', u'staples']),\n",
       " Row(clean_text=[u'ECOB', u'Cheap', u'stock', u'at', u'0002', u'LotteryTicket', u'ready', u'to', u'lift', u'finally', u'Lockout', u'in', u'place', u'Sales', u'HomeDepot', u'Lowes', u'RT'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5806"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove retweets and duplicates\n",
    "corpus.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = corpus.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds: 2.95780515671\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "all_docs = corpus.toPandas()['clean_text'].values.tolist()#.collect()\n",
    "print \"seconds:\", time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.347715854645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "vec_list = []\n",
    "tweet = []\n",
    "for doc in all_docs:\n",
    "    docvec = average_word_vecs(doc)\n",
    "    if docvec == None:\n",
    "        continue\n",
    "    else:\n",
    "        vec_list.append(docvec)\n",
    "        tweet.append(doc)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4914"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4914"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.5452730656\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cluster_results = cosine_cluster(vec_list, .7)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for index, clus in enumerate(cluster_results):\n",
    "    clusters.append((index, len(clus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters.sort(cmp=None,key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2102),\n",
       " (12, 457),\n",
       " (20, 423),\n",
       " (10, 318),\n",
       " (19, 251),\n",
       " (5, 230),\n",
       " (22, 129),\n",
       " (3, 121),\n",
       " (25, 107),\n",
       " (141, 94)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster numbers and lengths\n",
    "clusters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster number:1 Cluster size:2102\n",
      "keywords: [(u'tension relieving force', 9.0), (u'indoor bug protection', 8.666666666666666), (u'mplusplaces download today', 7.766666666666666), (u'latest baby news', 7.619047619047619), (u'major trump supporter', 7.583333333333334), (u'innovation end cap', 7.111111111111111), (u'lowes gift cards', 6.984452122408687), (u'lowes hires man', 6.734452122408687), (u'lowes parking lot', 6.688997576954142), (u'local hardware store', 6.2606958762886595)] \n",
      "\n",
      "Cluster number:12 Cluster size:457\n",
      "keywords: [(u'franco morbidelli completed', 9.0), (u'replace bradley smith', 9.0), (u'armour hat cap', 9.0), (u'making motogp debu', 8.5), (u'complete motogp rider', 8.5), (u'armour nascar race', 8.166666666666666), (u'kalex moto mac', 8.0), (u'donington alex lowes', 7.9), (u'motogp racing motorsports', 7.5), (u'zarco lowes 2nd', 6.9)] \n",
      "\n",
      "Cluster number:20 Cluster size:423\n",
      "keywords: [(u'favorite sh big', 9.0), (u'donthecon triggers call', 9.0), (u'peak lab rescues', 9.0), (u'favorite gwyneth paltrow', 9.0), (u'donating blue lights', 9.0), (u'bissell bagless vacuum', 9.0), (u'approached young girl', 9.0), (u'edition judy judy', 9.0), (u'middle finger ill', 9.0), (u'applique engineering rocks', 9.0)] \n",
      "\n",
      "Cluster number:10 Cluster size:318\n",
      "keywords: [(u'blue buy discount', 9.0), (u'cross streets wash', 9.0), (u'steal eagle hardware', 9.0), (u'omg congrats im', 9.0), (u'rob lowes roast', 8.0), (u'lowes ace menards', 8.0), (u'actress katie lowes', 8.0), (u'free shipping bid', 7.266666666666667), (u'home depot bid', 7.266666666666667), (u'lowes coupons valid', 7.0)] \n",
      "\n",
      "Cluster number:19 Cluster size:251\n",
      "keywords: [(u'marini cortese kent', 9.0), (u'marquez esp kalex', 9.0), (u'gp secara perlahan', 9.0), (u'morbidelli', 1.0), (u'aancawang', 1.0), (u'237 folger +0', 1.0)] \n",
      "\n",
      "Cluster number:5 Cluster size:230\n",
      "keywords: [(u'congressman al green', 9.0), (u'rivers kinda guy', 9.0), (u'official recognition boy', 9.0), (u'department aisle psa', 9.0), (u'simple steps goals', 9.0), (u'replys arent canned', 9.0), (u'tabias john asked', 9.0), (u'snows real bad', 9.0), (u'body gettin hiii', 9.0), (u'vernon hills il', 9.0)] \n",
      "\n",
      "Cluster number:22 Cluster size:129\n",
      "keywords: [(u'moto czechgp dios', 9.0), (u'sp forza morbidelli', 9.0), (u'huffpostquebec folger lleva', 9.0), (u'lowes donald riendeau', 8.75), (u'homedepot lowes mort', 8.75), (u'lowes ce week', 8.75), (u'resbalon de rins', 8.5), (u'lowes con 2', 4.75), (u'cara de', 4.5), (u'ser pobre', 4.0)] \n",
      "\n",
      "Cluster number:3 Cluster size:121\n",
      "keywords: [(u'free priorty shipping', 9.0), (u'gift card free', 8.333333333333334), (u'lowes merchandise credit', 8.0), (u'ships fast bid', 7.379310344827586), (u'5 clarcksville apply', 4.0), (u'card bid', 3.71264367816092), (u'expiration bid', 3.3793103448275863), (u'00 lowes bid', 3.3793103448275863), (u'locations bid', 3.3793103448275863), (u'tracking bid', 3.3793103448275863)] \n",
      "\n",
      "Cluster number:25 Cluster size:107\n",
      "keywords: [(u'dealaction freeshippingday papaya', 9.0), (u'plover wi painting', 9.0), (u'rochester hills mi', 9.0), (u'@511nyalbany update incident', 9.0), (u'north east md', 9.0), (u'el capitan theatre', 9.0), (u'rita ora partying', 9.0), (u'waterloo ia back', 9.0), (u'white lake mi', 9.0), (u'sterling height mi', 9.0)] \n",
      "\n",
      "Cluster number:141 Cluster size:94\n",
      "keywords: [(u'finish special guest', 9.0), (u'gamings greatest dreamers', 9.0), (u'bradford bulls coach', 9.0), (u'bradl super stuff', 9.0), (u'personal reasons chroniclelive', 9.0), (u'personal reasons sport', 9.0), (u'american film market', 9.0), (u'rafa bentez chats', 9.0), (u'life sheppards hook', 9.0), (u'make gp debut', 9.0)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_characters = 3\n",
    "max_phrase = 3\n",
    "remove_repeats = True\n",
    "for tup in clusters[:10]:\n",
    "    tweet_list = []\n",
    "    for index in cluster_results[tup[0]]:\n",
    "        tweet_list.append(tweet[index])\n",
    "    print 'Cluster number:{}'.format(tup[0]), \"Cluster size:{}\".format(tup[1])\n",
    "    print \"keywords:\", keyword_extractor.keywords_from_tweet_list(tweet_list,num_characters, max_phrase,remove_repeats)[:10], \"\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
